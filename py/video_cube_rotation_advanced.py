"""
å¤šè§†é¢‘ç«‹æ–¹ä½“æ—‹è½¬æ•ˆæœèŠ‚ç‚¹ - é«˜çº§æ··åˆæ¶æ„ç‰ˆæœ¬
çœŸæ­£çš„3DæŠ•å½±è®¡ç®— + OpenCVåˆæˆ
"""

import torch
import cv2
import numpy as np
from PIL import Image
from comfy.comfy_types.node_typing import ComfyNodeABC, InputTypeDict, IO
from .playwright_renderer import PlaywrightRenderer


class VideoCubeRotationAdvancedNode(ComfyNodeABC):
    """å¤šè§†é¢‘ç«‹æ–¹ä½“æ—‹è½¬æ•ˆæœèŠ‚ç‚¹ - é«˜çº§æ··åˆæ¶æ„ç‰ˆæœ¬"""
    
    CATEGORY = "VideoTransition"
    
    @classmethod
    def INPUT_TYPES(cls) -> InputTypeDict:
        return {
            "required": {
                "rotation_style": ([
                    "x_axis",           # ç»•Xè½´æ—‹è½¬
                    "y_axis",           # ç»•Yè½´æ—‹è½¬
                    "z_axis",           # ç»•Zè½´æ—‹è½¬
                    "diagonal",         # å¯¹è§’çº¿æ—‹è½¬
                    "random_spin",      # éšæœºæ—‹è½¬
                    "cube_unfold",      # ç«‹æ–¹ä½“å±•å¼€
                ],),
                "rotation_speed": (IO.FLOAT, {"default": 1.0, "min": 0.1, "max": 5.0, "step": 0.1}),
                "duration": (IO.FLOAT, {"default": 5.0, "min": 1.0, "max": 30.0, "step": 0.1}),
                "fps": (IO.INT, {"default": 30, "min": 15, "max": 60}),
            },
            "optional": {
                "video_front": (IO.IMAGE,),   # å‰é¢è§†é¢‘
                "video_back": (IO.IMAGE,),    # åé¢è§†é¢‘
                "video_left": (IO.IMAGE,),    # å·¦é¢è§†é¢‘
                "video_right": (IO.IMAGE,),   # å³é¢è§†é¢‘
                "video_top": (IO.IMAGE,),     # ä¸Šé¢è§†é¢‘
                "video_bottom": (IO.IMAGE,),  # ä¸‹é¢è§†é¢‘
                "background_color": (IO.STRING, {"default": "#1a1a2e"}),
                "width": (IO.INT, {"default": 640, "min": 640, "max": 3840}),
                "height": (IO.INT, {"default": 640, "min": 360, "max": 2160}),
                "cube_size": (IO.FLOAT, {"default": 0.6, "min": 0.3, "max": 1.0}),
                "perspective": (IO.FLOAT, {"default": 1000.0, "min": 500.0, "max": 3000.0}),
            }
        }
    
    RETURN_TYPES = (IO.IMAGE,)
    RETURN_NAMES = ("video",)
    FUNCTION = "generate_video_cube_rotation"
    
    def __init__(self):
        # ç«‹æ–¹ä½“çš„8ä¸ªé¡¶ç‚¹ï¼ˆ3Dåæ ‡ï¼‰
        self.cube_vertices = np.array([
            [-1, -1, -1],  # 0: å·¦åä¸‹
            [ 1, -1, -1],  # 1: å³åä¸‹
            [ 1,  1, -1],  # 2: å³å‰ä¸‹
            [-1,  1, -1],  # 3: å·¦å‰ä¸‹
            [-1, -1,  1],  # 4: å·¦åä¸Š
            [ 1, -1,  1],  # 5: å³åä¸Š
            [ 1,  1,  1],  # 6: å³å‰ä¸Š
            [-1,  1,  1],  # 7: å·¦å‰ä¸Š
        ], dtype=np.float32)
        
        # ç«‹æ–¹ä½“çš„6ä¸ªé¢ï¼ˆæ¯ä¸ªé¢4ä¸ªé¡¶ç‚¹ç´¢å¼•ï¼‰
        self.cube_faces = [
            [0, 1, 2, 3],  # å‰é¢ (front)
            [4, 7, 6, 5],  # åé¢ (back)
            [1, 5, 6, 2],  # å³é¢ (right)
            [4, 0, 3, 7],  # å·¦é¢ (left)
            [3, 2, 6, 7],  # ä¸Šé¢ (top)
            [4, 5, 1, 0],  # ä¸‹é¢ (bottom)
        ]
        
        # é¢åç§°æ˜ å°„
        self.face_names = ['front', 'back', 'right', 'left', 'top', 'bottom']
    
    async def generate_video_cube_rotation(
        self, 
        rotation_style, 
        rotation_speed, 
        duration, 
        fps,
        video_front=None,
        video_back=None,
        video_left=None,
        video_right=None,
        video_top=None,
        video_bottom=None,
        background_color="#1a1a2e",
        width=1920,
        height=1080,
        cube_size=0.6,
        perspective=1000.0
    ):
        """ç”Ÿæˆå¤šè§†é¢‘ç«‹æ–¹ä½“æ—‹è½¬æ•ˆæœ - é«˜çº§æ··åˆæ¶æ„"""
        
        print(f"ğŸ¬ å¼€å§‹ç”Ÿæˆå¤šè§†é¢‘ç«‹æ–¹ä½“æ—‹è½¬æ•ˆæœ (é«˜çº§æ··åˆæ¶æ„): {rotation_style}")
        
        # å¤„ç†6ä¸ªé¢çš„è§†é¢‘æ•°æ®
        video_frames_data = self._process_cube_videos(
            video_front, video_back, video_left, video_right, video_top, video_bottom
        )
        
        print(f"ğŸ“¹ è§†é¢‘ç«‹æ–¹ä½“ä¿¡æ¯:")
        for i, frames in enumerate(video_frames_data):
            print(f"   - {self.face_names[i]}: {len(frames)}å¸§")
        
        # è®¡ç®—æ€»å¸§æ•°
        total_frames = int(duration * fps)
        
        # çº¯Pythonæ¸²æŸ“ï¼ˆä¸ä½¿ç”¨Playwrightï¼‰
        video_tensor = self._render_with_opencv(
            video_frames_data, rotation_style, rotation_speed,
            total_frames, width, height, cube_size, perspective, background_color
        )
        
        return (video_tensor,)
    
    def _process_cube_videos(self, video_front, video_back, video_left, video_right, video_top, video_bottom):
        """å¤„ç†6ä¸ªé¢çš„è§†é¢‘æ•°æ®ï¼Œè½¬æ¢ä¸ºnumpyæ•°ç»„"""
        video_frames_data = []
        videos = [video_front, video_back, video_left, video_right, video_top, video_bottom]
        
        for i, video_tensor in enumerate(videos):
            if video_tensor is not None:
                if video_tensor.dim() == 4:
                    batch_size = video_tensor.shape[0]
                    print(f"   å¤„ç† {self.face_names[i]} tensor: {video_tensor.shape}")
                    
                    frames = []
                    for j in range(batch_size):
                        frame_tensor = video_tensor[j]  # [H, W, C]
                        frame_np = self._tensor_to_numpy(frame_tensor)
                        frames.append(frame_np)
                    
                    video_frames_data.append(frames)
                else:
                    raise ValueError(f"{self.face_names[i]}è§†é¢‘tensorå¿…é¡»æ˜¯4Dæ ¼å¼ [B, H, W, C]ï¼Œå½“å‰: {video_tensor.shape}")
            else:
                print(f"   {self.face_names[i]}: æœªæä¾›ï¼Œä½¿ç”¨é»˜è®¤é»‘è‰²å¸§")
                default_frame = np.zeros((512, 512, 3), dtype=np.uint8)
                video_frames_data.append([default_frame])
        
        return video_frames_data
    
    def _tensor_to_numpy(self, tensor):
        """å°†tensorè½¬æ¢ä¸ºnumpyæ•°ç»„"""
        if tensor.dim() == 4:
            tensor = tensor[0]
        
        array = tensor.cpu().numpy()
        
        if array.dtype in [np.float32, np.float64]:
            array = (array * 255).clip(0, 255).astype(np.uint8)
        elif array.dtype != np.uint8:
            array = array.astype(np.uint8)
        
        return array
    
    def _render_with_opencv(
        self, 
        video_frames_data, 
        rotation_style, 
        rotation_speed,
        total_frames, 
        width, 
        height, 
        cube_size, 
        perspective, 
        background_color
    ):
        """ä½¿ç”¨OpenCVè¿›è¡Œçº¯Pythonæ¸²æŸ“"""
        
        print(f"ğŸ”„ å¼€å§‹OpenCVæ¸²æŸ“ {total_frames} å¸§...")
        
        # è§£æèƒŒæ™¯é¢œè‰²
        bg_color = self._parse_background_color(background_color)
        
        frames = []
        
        for i in range(total_frames):
            progress = i / max(total_frames - 1, 1)
            
            # åˆ›å»ºèƒŒæ™¯
            frame = np.full((height, width, 3), bg_color, dtype=np.uint8)
            
            # è®¡ç®—æ—‹è½¬çŸ©é˜µ
            rotation_matrix = self._calculate_rotation_matrix(rotation_style, progress, rotation_speed)
            
            # æ¸²æŸ“ç«‹æ–¹ä½“
            self._render_cube(frame, video_frames_data, rotation_matrix, progress, cube_size, perspective, width, height)
            
            # è½¬æ¢ä¸ºtensor
            frame_tensor = torch.from_numpy(frame.astype(np.float32) / 255.0)
            frames.append(frame_tensor)
            
            # è¿›åº¦æç¤º
            if (i + 1) % 10 == 0 or i == total_frames - 1:
                print(f"   æ¸²æŸ“è¿›åº¦: {i + 1}/{total_frames} ({(i + 1) / total_frames * 100:.1f}%)")
        
        # å †å ä¸ºè§†é¢‘tensor
        video_tensor = torch.stack(frames, dim=0)
        print(f"âœ… OpenCVæ¸²æŸ“å®Œæˆï¼è¾“å‡ºå½¢çŠ¶: {video_tensor.shape}")
        
        return video_tensor
    
    def _parse_background_color(self, color_str):
        """è§£æèƒŒæ™¯é¢œè‰²å­—ç¬¦ä¸²"""
        if color_str.startswith('#'):
            # åå…­è¿›åˆ¶é¢œè‰²
            hex_color = color_str[1:]
            r = int(hex_color[0:2], 16)
            g = int(hex_color[2:4], 16)
            b = int(hex_color[4:6], 16)
            return [b, g, r]  # OpenCVä½¿ç”¨BGRæ ¼å¼
        else:
            # é»˜è®¤é»‘è‰²
            return [0, 0, 0]
    
    def _calculate_rotation_matrix(self, rotation_style, progress, rotation_speed):
        """è®¡ç®—æ—‹è½¬çŸ©é˜µ"""
        angle = progress * 360 * rotation_speed
        
        if rotation_style == 'x_axis':
            return self._rotation_matrix_x(np.radians(angle))
        elif rotation_style == 'y_axis':
            return self._rotation_matrix_y(np.radians(angle))
        elif rotation_style == 'z_axis':
            return self._rotation_matrix_z(np.radians(angle))
        elif rotation_style == 'diagonal':
            rx = self._rotation_matrix_x(np.radians(angle * 0.7))
            ry = self._rotation_matrix_y(np.radians(angle))
            return np.dot(ry, rx)
        elif rotation_style == 'random_spin':
            rx = self._rotation_matrix_x(np.radians(angle * 0.6))
            ry = self._rotation_matrix_y(np.radians(angle * 1.0))
            rz = self._rotation_matrix_z(np.radians(angle * 0.3))
            return np.dot(rz, np.dot(ry, rx))
        elif rotation_style == 'cube_unfold':
            if progress < 0.5:
                return self._rotation_matrix_y(np.radians(progress * 2 * 180))
            else:
                unfold_progress = (progress - 0.5) * 2
                return self._rotation_matrix_y(np.radians(180 + unfold_progress * 180))
        else:
            return self._rotation_matrix_y(np.radians(angle))
    
    def _rotation_matrix_x(self, angle):
        """ç»•Xè½´æ—‹è½¬çŸ©é˜µ"""
        cos_a, sin_a = np.cos(angle), np.sin(angle)
        return np.array([
            [1, 0, 0],
            [0, cos_a, -sin_a],
            [0, sin_a, cos_a]
        ], dtype=np.float32)
    
    def _rotation_matrix_y(self, angle):
        """ç»•Yè½´æ—‹è½¬çŸ©é˜µ"""
        cos_a, sin_a = np.cos(angle), np.sin(angle)
        return np.array([
            [cos_a, 0, sin_a],
            [0, 1, 0],
            [-sin_a, 0, cos_a]
        ], dtype=np.float32)
    
    def _rotation_matrix_z(self, angle):
        """ç»•Zè½´æ—‹è½¬çŸ©é˜µ"""
        cos_a, sin_a = np.cos(angle), np.sin(angle)
        return np.array([
            [cos_a, -sin_a, 0],
            [sin_a, cos_a, 0],
            [0, 0, 1]
        ], dtype=np.float32)
    
    def _render_cube(self, frame, video_frames_data, rotation_matrix, progress, cube_size, perspective, width, height):
        """æ¸²æŸ“ç«‹æ–¹ä½“"""
        
        # ç¼©æ”¾ç«‹æ–¹ä½“
        scale = cube_size * min(width, height) / 4
        vertices = self.cube_vertices * scale
        
        # åº”ç”¨æ—‹è½¬
        rotated_vertices = np.dot(vertices, rotation_matrix.T)
        
        # é€è§†æŠ•å½±
        projected_vertices = self._perspective_projection(rotated_vertices, perspective, width, height)
        
        # æ¸²æŸ“æ¯ä¸ªé¢
        for face_idx, face_vertex_indices in enumerate(self.cube_faces):
            if face_idx < len(video_frames_data) and video_frames_data[face_idx]:
                self._render_face(frame, face_vertex_indices, projected_vertices, 
                                video_frames_data[face_idx], progress, face_idx)
    
    def _perspective_projection(self, vertices, perspective, width, height):
        """é€è§†æŠ•å½±"""
        # å°†3Dç‚¹æŠ•å½±åˆ°2Då±å¹•
        projected = np.zeros((len(vertices), 2), dtype=np.float32)
        
        for i, vertex in enumerate(vertices):
            if vertex[2] + perspective > 0:  # é¿å…é™¤é›¶
                # é€è§†æŠ•å½±
                x = (vertex[0] * perspective) / (vertex[2] + perspective)
                y = (vertex[1] * perspective) / (vertex[2] + perspective)
                
                # è½¬æ¢åˆ°å±å¹•åæ ‡
                projected[i][0] = x + width / 2
                projected[i][1] = y + height / 2
        
        return projected
    
    def _render_face(self, frame, face_vertex_indices, projected_vertices, face_frames, progress, face_idx):
        """æ¸²æŸ“ç«‹æ–¹ä½“çš„ä¸€ä¸ªé¢"""
        
        # è·å–é¢çš„4ä¸ªé¡¶ç‚¹
        face_vertices = projected_vertices[face_vertex_indices]
        
        # æ£€æŸ¥é¢æ˜¯å¦å¯è§ï¼ˆç®€å•çš„èƒŒé¢å‰”é™¤ï¼‰
        if not self._is_face_visible(face_vertices):
            return
        
        # è®¡ç®—å½“å‰å¸§ç´¢å¼•
        total_frames = len(face_frames)
        frame_index = int(progress * (total_frames - 1))
        frame_index = max(0, min(frame_index, total_frames - 1))
        
        # è·å–å½“å‰å¸§
        current_frame = face_frames[frame_index]
        
        # åˆ›å»ºå˜æ¢çŸ©é˜µ
        src_points = np.array([
            [0, 0],
            [current_frame.shape[1], 0],
            [current_frame.shape[1], current_frame.shape[0]],
            [0, current_frame.shape[0]]
        ], dtype=np.float32)
        
        dst_points = face_vertices.astype(np.float32)
        
        # è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
        try:
            transform_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
            
            # åº”ç”¨é€è§†å˜æ¢
            warped = cv2.warpPerspective(current_frame, transform_matrix, (frame.shape[1], frame.shape[0]))
            
            # åˆ›å»ºæ©ç 
            mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)
            cv2.fillPoly(mask, [dst_points.astype(np.int32)], 255)
            
            # åˆæˆåˆ°å¸§ä¸Š
            frame[mask > 0] = warped[mask > 0]
            
        except cv2.error:
            # å¦‚æœå˜æ¢å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªé¢
            pass
    
    def _is_face_visible(self, face_vertices):
        """ç®€å•çš„èƒŒé¢å‰”é™¤"""
        # è®¡ç®—é¢çš„æ³•å‘é‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        v1 = face_vertices[1] - face_vertices[0]
        v2 = face_vertices[2] - face_vertices[0]
        
        # å‰ç§¯è®¡ç®—æ³•å‘é‡
        normal_z = v1[0] * v2[1] - v1[1] * v2[0]
        
        # å¦‚æœæ³•å‘é‡æŒ‡å‘å±å¹•å¤–ï¼Œåˆ™é¢ä¸å¯è§
        return normal_z > 0


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "VideoCubeRotationAdvancedNode": VideoCubeRotationAdvancedNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoCubeRotationAdvancedNode": "Multi-video cube rotation",
}

