"""
è§†é¢‘ç«‹æ–¹ä½“è½¬åœºèŠ‚ç‚¹ - Playwrightç‰ˆæœ¬ï¼ˆæ‰¹å¤„ç†ä¼˜åŒ–ï¼‰
ä¸¤ä¸ªè§†é¢‘ç‰‡æ®µä¹‹é—´çš„3Dç«‹æ–¹ä½“æ—‹è½¬è½¬åœºæ•ˆæœï¼Œæ”¯æŒæ‰¹å¤„ç†å’Œå†…å­˜ä¼˜åŒ–
"""

import torch
import json
import cv2
import numpy as np
import math
import time
from comfy.comfy_types.node_typing import ComfyNodeABC, InputTypeDict, IO


class VideoCubeTransitionNode(ComfyNodeABC):
    """è§†é¢‘ç«‹æ–¹ä½“è½¬åœº - ä¸¤ä¸ªè§†é¢‘ä¹‹é—´çš„3Dç«‹æ–¹ä½“æ—‹è½¬è½¬åœºï¼ˆæ‰¹å¤„ç†ä¼˜åŒ–ç‰ˆï¼‰"""
    
    CATEGORY = "VideoTransition"
    
    @classmethod
    def INPUT_TYPES(cls) -> InputTypeDict:
        return {
            "required": {
                "video1": (IO.IMAGE,),  # ç¬¬ä¸€ä¸ªè§†é¢‘ï¼ˆç«‹æ–¹ä½“æ­£é¢ï¼‰
                "video2": (IO.IMAGE,),  # ç¬¬äºŒä¸ªè§†é¢‘ï¼ˆç«‹æ–¹ä½“å¦ä¸€é¢ï¼‰
                "direction": ([
                    "horizontal",  # æ°´å¹³ç«‹æ–¹ä½“è½¬åœºï¼ˆå·¦å³è½¬ï¼‰
                    "vertical",    # å‚ç›´ç«‹æ–¹ä½“è½¬åœºï¼ˆä¸Šä¸‹è½¬ï¼‰
                ],),
                "total_frames": (IO.INT, {"default": 60, "min": 4, "max": 300}),
                "fps": (IO.INT, {"default": 30, "min": 15, "max": 60}),
            },
            "optional": {
                "rotation_angle": (IO.FLOAT, {"default": 90.0, "min": 45.0, "max": 180.0}),
                "cube_size": (IO.FLOAT, {"default": 300.0, "min": 200.0, "max": 600.0}),
                "perspective": (IO.FLOAT, {"default": 800.0, "min": 500.0, "max": 2000.0}),
                "use_gpu": (IO.BOOLEAN, {"default": False}),
                "batch_size": (IO.INT, {"default": 5, "min": 1, "max": 20}),
                "background_color": (IO.STRING, {"default": "#000000"}),
                "width": (IO.INT, {"default": 640, "min": 320, "max": 1920}),
                "height": (IO.INT, {"default": 640, "min": 240, "max": 1080}),
            }
        }
    
    RETURN_TYPES = (IO.IMAGE,)
    RETURN_NAMES = ("video",)
    FUNCTION = "generate_cube_transition"
    
    async def generate_cube_transition(
        self, 
        video1, 
        video2,
        direction,
        total_frames, 
        fps,
        rotation_angle=90.0,
        cube_size=300.0,
        perspective=800.0,
        use_gpu=False,
        batch_size=5,
        background_color="#000000",
        width=640,
        height=640
    ):
        """ç”Ÿæˆè§†é¢‘ç«‹æ–¹ä½“è½¬åœºæ•ˆæœ - æ‰¹å¤„ç†ä¼˜åŒ–ç‰ˆæœ¬"""
        
        start_time = time.time()
        print(f"Starting cube transition: {direction}, {total_frames} frames")
        
        # æå–è§†é¢‘å¸§
        frames1 = self._extract_video_frames(video1)
        frames2 = self._extract_video_frames(video2)
        print(f"Video frames: {len(frames1)} -> {len(frames2)}, generating {total_frames} transition frames")
        
        # ğŸ¯ ç«‹æ–¹ä½“é¢å°ºå¯¸ç›´æ¥ä½¿ç”¨ç”»å¸ƒå°ºå¯¸ï¼ˆçŸ©å½¢é¢ï¼‰
        cube_width = width
        cube_height = height
        
        # è§£æèƒŒæ™¯é¢œè‰²
        bg_color_bgr = self._parse_background_color(background_color)
        
        # é¢„è®¡ç®—ä¼˜åŒ–ï¼šæå‰è®¡ç®—æ‰€æœ‰å¸§çš„base64æ•°æ®
        precompute_start = time.time()
        
        frame1_base64_list = []
        frame2_base64_list = []
        
        for i in range(total_frames):
            progress = i / (total_frames - 1) if total_frames > 1 else 0
            
            # è·å–å¯¹åº”çš„å¸§
            if len(frames1) == 1:
                frame1_data = self._tensor_to_numpy(frames1[0])
            else:
                frame1_idx = min(int(progress * (len(frames1) - 1)), len(frames1) - 1)
                frame1_data = self._tensor_to_numpy(frames1[frame1_idx])
            
            if len(frames2) == 1:
                frame2_data = self._tensor_to_numpy(frames2[0])
            else:
                frame2_idx = min(int(progress * (len(frames2) - 1)), len(frames2) - 1)
                frame2_data = self._tensor_to_numpy(frames2[frame2_idx])
            
            # é¢„è®¡ç®—base64æ•°æ®
            frame1_base64_list.append(self._numpy_to_base64(frame1_data))
            frame2_base64_list.append(self._numpy_to_base64(frame2_data))
        
        precompute_time = time.time() - precompute_start
        
        # ä½¿ç”¨Playwrightç›´æ¥æ¸²æŸ“3Dæ•ˆæœ
        from playwright.async_api import async_playwright
        
        playwright = await async_playwright().start()
        
        try:
            # æ ¹æ®GPUè®¾ç½®é€‰æ‹©æ¸²æŸ“æ–¹å¼
            if use_gpu:
                print("Playwright browser starting with GPU acceleration")
                # GPUç¡¬ä»¶åŠ é€Ÿ
                browser = await playwright.chromium.launch(
                    headless=True,
                    args=[
                        '--enable-gpu',                    # å¯ç”¨GPU
                        '--use-gl=angle',                  # ä½¿ç”¨ANGLEï¼ˆæ”¯æŒGPUï¼‰
                        '--enable-webgl',
                        '--enable-accelerated-2d-canvas',
                        '--disable-dev-shm-usage',
                        '--hide-scrollbars',
                        '--mute-audio',
                        '--no-sandbox',                    # é¿å…æƒé™é—®é¢˜
                        '--disable-setuid-sandbox',
                    ]
                )
            else:
                print("Playwright browser starting with SwiftShader (CPU rendering)")
                # SwiftShaderè½¯ä»¶æ¸²æŸ“
                browser = await playwright.chromium.launch(
                    headless=True,
                    args=[
                        '--use-angle=swiftshader',         # å¼ºåˆ¶ä½¿ç”¨CPUè½¯ä»¶æ¸²æŸ“
                        '--enable-webgl',
                        '--enable-accelerated-2d-canvas',
                        '--disable-dev-shm-usage',
                        '--hide-scrollbars',
                        '--mute-audio',
                    ]
                )
            
            # ç”ŸæˆHTMLæ¨¡æ¿ï¼ˆä¼ é€’cube_widthã€cube_heightå’Œdirectionï¼‰
            html_content = self._generate_html_template(
                direction, rotation_angle, cube_width, cube_height, perspective, background_color, width, height
            )
            
            # åˆ›å»ºé¡µé¢
            page = await browser.new_page(viewport={'width': width, 'height': height})
            
            try:
                # åŠ è½½HTMLé¡µé¢
                await page.set_content(html_content, wait_until='domcontentloaded', timeout=30000)
                
                # ç­‰å¾…é¡µé¢åˆå§‹åŒ–
                await page.wait_for_function("window.cubeController && window.cubeController.ready", timeout=5000)
                
                # ä½¿ç”¨ç”Ÿæˆå™¨è¿›è¡Œå†…å­˜ä¼˜åŒ–
                output_frames = []
                render_start = time.time()
                
                for batch_start in range(0, total_frames, batch_size):
                    batch_end = min(batch_start + batch_size, total_frames)
                    batch_indices = list(range(batch_start, batch_end))
                    
                    # æ‰¹å¤„ç†ï¼šä¸€æ¬¡å¤„ç†å¤šä¸ªå¸§
                    batch_frames = await self._process_batch(
                        page, batch_indices, frame1_base64_list, frame2_base64_list, total_frames, rotation_angle
                    )
                    
                    # ç«‹å³æ·»åŠ åˆ°ç»“æœä¸­ï¼Œé¿å…å†…å­˜ç§¯ç´¯
                    output_frames.extend(batch_frames)
                    
                    # æ˜¾ç¤ºè¿›åº¦ - æ¯2ä¸ªæ‰¹æ¬¡æˆ–å®Œæˆæ—¶æ˜¾ç¤º
                    if batch_end % (batch_size * 2) == 0 or batch_end == total_frames:
                        progress = (batch_end / total_frames) * 100
                        elapsed = time.time() - render_start
                        if batch_end < total_frames:
                            eta = (elapsed / batch_end) * (total_frames - batch_end)
                            print(f"Processing frames {batch_end}/{total_frames} ({progress:.1f}%) - ETA: {eta:.1f}s")
                        else:
                            print(f"Rendering completed: {batch_end}/{total_frames} frames in {elapsed:.2f}s")
                
                render_time = time.time() - render_start
            
            finally:
                await page.close()
            
            await browser.close()
        finally:
            await playwright.stop()
        
        # è½¬æ¢ä¸ºtensor
        video_tensor = self._frames_to_tensor(output_frames)
        
        total_time = time.time() - start_time
        print(f"Cube transition completed: {video_tensor.shape} in {total_time:.2f}s")
        
        return (video_tensor,)
    
    async def _process_batch(self, page, batch_indices, frame1_base64_list, frame2_base64_list, total_frames, rotation_angle):
        """æ‰¹å¤„ç†æ¸²æŸ“å¤šä¸ªå¸§"""
        batch_frames = []
        
        for i in batch_indices:
            progress = i / (total_frames - 1) if total_frames > 1 else 0
            
            # ä½¿ç”¨é¢„è®¡ç®—çš„base64æ•°æ®
            frame1_base64 = frame1_base64_list[i]
            frame2_base64 = frame2_base64_list[i]
            
            # æ›´æ–°ç«‹æ–¹ä½“é¢çš„èƒŒæ™¯å›¾ç‰‡å’Œæ—‹è½¬
            await page.evaluate(f"""
                const frontFace = document.getElementById('frontFace');
                const secondFace = document.getElementById('secondFace');
                
                if (frontFace) {{
                    frontFace.style.backgroundImage = 'url({frame1_base64})';
                }}
                
                if (secondFace) {{
                    secondFace.style.backgroundImage = 'url({frame2_base64})';
                }}
                
                // æ›´æ–°æ—‹è½¬
                if (window.cubeController) {{
                    window.cubeController.updateRotation({progress});
                }}
            """)
            
            # ä¼˜åŒ–ç­‰å¾…æ—¶é—´
            await page.wait_for_timeout(20)  # ä»200mså‡å°‘åˆ°20ms
            
            # å¼ºåˆ¶è§¦å‘é‡ç»˜
            await page.evaluate("document.body.offsetHeight")
            
            # ç­‰å¾…CSSåŠ¨ç”»å®Œæˆ
            await page.wait_for_timeout(10)  # ä»50mså‡å°‘åˆ°10ms
            
            # ä¼˜åŒ–æˆªå›¾ï¼šä½¿ç”¨JPEGæ ¼å¼
            screenshot_bytes = await page.screenshot(type='jpeg', quality=85)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            from PIL import Image
            import io
            image = Image.open(io.BytesIO(screenshot_bytes)).convert('RGB')
            final_frame = np.array(image).astype(np.uint8)
            
            batch_frames.append(final_frame)
        
        return batch_frames
    
    def _generate_html_template(self, direction, rotation_angle, cube_width, cube_height, perspective, background_color, width, height):
        """ç”ŸæˆHTMLæ¨¡æ¿ - çŸ©å½¢ç«‹æ–¹ä½“é¢ï¼ˆæ”¯æŒæ°´å¹³å’Œå‚ç›´æ–¹å‘ï¼‰"""
        
        # æ ¹æ®æ–¹å‘è®¾ç½®ç«‹æ–¹ä½“é¢çš„å˜æ¢
        if direction == "horizontal":
            # æ°´å¹³ç«‹æ–¹ä½“ï¼ˆå·¦å³è½¬ï¼‰ï¼šæ­£é¢ + å³ä¾§é¢
            # æ·±åº¦ä½¿ç”¨å®½åº¦çš„ä¸€åŠ
            cube_depth = cube_width / 2
            front_transform = f"translateZ({cube_depth}px)"
            second_face_transform = f"rotateY(90deg) translateZ({cube_depth}px)"
            second_face_class = "right"
        else:
            # å‚ç›´ç«‹æ–¹ä½“ï¼ˆä¸Šä¸‹è½¬ï¼‰ï¼šæ­£é¢ + åº•é¢
            # æ·±åº¦ä½¿ç”¨é«˜åº¦çš„ä¸€åŠï¼ˆé‡è¦ï¼ï¼‰
            cube_depth = cube_height / 2
            front_transform = f"translateZ({cube_depth}px)"
            second_face_transform = f"rotateX(90deg) translateZ({cube_depth}px)"
            second_face_class = "bottom"
        
        return f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            width: {width}px;
            height: {height}px;
            background: {background_color};
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            perspective: {perspective}px;
            perspective-origin: 50% 50%;
        }}
        
        .cube-container {{
            width: {cube_width}px;
            height: {cube_height}px;
            position: relative;
            transform-style: preserve-3d;
            transform: rotateY(0deg);
        }}
        
        .cube-face {{
            position: absolute;
            width: {cube_width + 1}px;
            height: {cube_height}px;
            backface-visibility: hidden;
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
            border: none;
            left: -0.5px;
        }}
        
        .front {{
            transform: {front_transform};
        }}
        
        .{second_face_class} {{
            transform: {second_face_transform};
        }}
    </style>
</head>
<body>
    <div class="cube-container" id="cubeContainer">
        <div class="cube-face front" id="frontFace"></div>
        <div class="cube-face {second_face_class}" id="secondFace"></div>
    </div>
    
    <script>
        class CubeController {{
            constructor() {{
                this.container = document.getElementById('cubeContainer');
                this.frontFace = document.getElementById('frontFace');
                this.secondFace = document.getElementById('secondFace');
                this.cubeWidth = {cube_width};
                this.cubeHeight = {cube_height};
                this.cubeDepth = {cube_depth};
                this.rotationAngle = {rotation_angle};
                this.direction = '{direction}';
                this.currentAngle = 0;
                this.ready = true;
                
                // console.log('ğŸ¬ CubeController initialized, direction=' + this.direction + ', size=' + this.cubeWidth + 'x' + this.cubeHeight);
            }}
            
            updateRotation(progress) {{
                // progress: 0 -> 1
                const angle = progress * this.rotationAngle;
                this.currentAngle = angle;
                
                // ğŸ¯ ä¼˜åŒ–ç¼©æ”¾æ›²çº¿ï¼šå¼€å§‹å’Œç»“æŸå¡«æ»¡ç”»å¸ƒï¼Œä¸­é—´ç¼©å°æ˜¾ç¤ºç«‹æ–¹ä½“3Dæ•ˆæœ
                // ä½¿ç”¨å¹³æ»‘çš„sinæ›²çº¿ï¼š1.0 -> 0.65 -> 1.0
                let scale;
                if (progress < 0.05) {{
                    // é˜¶æ®µ1ï¼ˆ0 -> 0.05ï¼‰ï¼šä¿æŒå®Œæ•´æ˜¾ç¤º
                    scale = 1.0;
                }} else if (progress > 0.95) {{
                    // é˜¶æ®µ4ï¼ˆ0.95 -> 1.0ï¼‰ï¼šæ¢å¤å®Œæ•´æ˜¾ç¤º
                    scale = 1.0;
                }} else {{
                    // é˜¶æ®µ2-3ï¼ˆ0.05 -> 0.95ï¼‰ï¼šä½¿ç”¨sinæ›²çº¿å¹³æ»‘ç¼©æ”¾
                    // å°†progressæ˜ å°„åˆ°0-Ï€èŒƒå›´ï¼Œsin(x)ä»0åˆ°1å†åˆ°0
                    const t = (progress - 0.05) / 0.9;  // å½’ä¸€åŒ–åˆ°0-1
                    const sinValue = Math.sin(t * Math.PI);  // 0 -> 1 -> 0
                    scale = 1.0 - (sinValue * 0.35);  // 1.0 -> 0.65 -> 1.0
                }}
                
                // æ ¹æ®æ–¹å‘é€‰æ‹©æ—‹è½¬è½´
                let rotateTransform;
                if (this.direction === 'horizontal') {{
                    // æ°´å¹³ç«‹æ–¹ä½“ï¼šç»•Yè½´æ—‹è½¬ï¼ˆå·¦å³è½¬ï¼‰
                    rotateTransform = `rotateY(${{-angle}}deg)`;
                }} else {{
                    // å‚ç›´ç«‹æ–¹ä½“ï¼šç»•Xè½´æ—‹è½¬ï¼ˆä¸Šä¸‹è½¬ï¼‰
                    rotateTransform = `rotateX(${{-angle}}deg)`;
                }}
                
                // åŒæ—¶åº”ç”¨æ—‹è½¬å’Œç¼©æ”¾
                const transform = `${{rotateTransform}} scale(${{scale}})`;
                this.container.style.transform = transform;
                
                // å¼ºåˆ¶é‡ç»˜
                void this.container.offsetHeight;
                
                // console.log(`[JS] Update: direction=${{this.direction}}, angle=${{angle.toFixed(1)}}Â°, scale=${{scale.toFixed(2)}}, transform=${{transform}}`);
            }}
            
            getFaceTransforms() {{
                const frontRect = this.frontFace.getBoundingClientRect();
                const secondRect = this.secondFace.getBoundingClientRect();
                
                // è·å–è®¡ç®—åçš„å˜æ¢çŸ©é˜µ
                const frontStyle = window.getComputedStyle(this.frontFace);
                const secondStyle = window.getComputedStyle(this.secondFace);
                
                return {{
                    front: {{
                        rect: {{
                            x: frontRect.x,
                            y: frontRect.y,
                            width: frontRect.width,
                            height: frontRect.height
                        }},
                        transform: frontStyle.transform,
                        visible: this._isFaceVisible(this.frontFace),
                        zIndex: this._calculateZIndex(frontStyle.transform)
                    }},
                    second: {{
                        rect: {{
                            x: secondRect.x,
                            y: secondRect.y,
                            width: secondRect.width,
                            height: secondRect.height
                        }},
                        transform: secondStyle.transform,
                        visible: this._isFaceVisible(this.secondFace),
                        zIndex: this._calculateZIndex(secondStyle.transform)
                    }},
                    currentAngle: this.currentAngle
                }};
            }}
            
            _isFaceVisible(element) {{
                const style = window.getComputedStyle(element);
                const transform = style.transform;
                
                if (transform === 'none') return true;
                
                const matrix = this._parseMatrix(transform);
                if (!matrix) return true;
                
                // 3DçŸ©é˜µçš„èƒŒé¢å‰”é™¤
                if (matrix.length === 16) {{
                    // matrix3d: æ£€æŸ¥Zè½´æ–¹å‘
                    const m11 = matrix[0], m12 = matrix[1], m13 = matrix[2];
                    const m21 = matrix[4], m22 = matrix[5], m23 = matrix[6];
                    const m31 = matrix[8], m32 = matrix[9], m33 = matrix[10];
                    
                    // è®¡ç®—æ³•å‘é‡çš„Zåˆ†é‡
                    const normalZ = m31;
                    return normalZ >= -0.1; // é¢å‘è§‚å¯Ÿè€…
                }}
                
                return true;
            }}
            
            _calculateZIndex(transformStr) {{
                if (transformStr === 'none') return 0;
                
                const matrix = this._parseMatrix(transformStr);
                if (!matrix) return 0;
                
                // è¿”å›Zè½´çš„translateZå€¼
                if (matrix.length === 16) {{
                    return matrix[14]; // matrix3dçš„Zå¹³ç§»
                }}
                
                return 0;
            }}
            
            _parseMatrix(matrixString) {{
                if (matrixString === 'none') return null;
                const values = matrixString.match(/matrix.*?\\((.+)\\)/);
                if (!values) return null;
                return values[1].split(/,\\s*/).map(parseFloat);
            }}
        }}
        
        window.cubeController = new CubeController();
        // console.log('âœ… CubeController initialized');
    </script>
</body>
</html>
"""
    
    def _compose_frame_with_opencv(self, frame1_data, frame2_data, cube_transforms, bg_color_bgr, width, height, cube_size):
        """ä½¿ç”¨OpenCVåˆæˆæœ€ç»ˆå¸§ - ä½¿ç”¨é€è§†å˜æ¢"""
        
        # åˆ›å»ºèƒŒæ™¯ç”»å¸ƒ
        canvas = np.full((height, width, 3), bg_color_bgr, dtype=np.uint8)
        
        # è°ƒæ•´è§†é¢‘å¸§å¤§å°åˆ°ç«‹æ–¹ä½“å°ºå¯¸
        frame1_resized = cv2.resize(frame1_data, (cube_size, cube_size), interpolation=cv2.INTER_AREA)
        frame2_resized = cv2.resize(frame2_data, (cube_size, cube_size), interpolation=cv2.INTER_AREA)
        
        # ç»˜åˆ¶ç«‹æ–¹ä½“çš„ä¸¤ä¸ªé¢
        faces_to_draw = []
        
        # æ­£é¢ï¼ˆvideo1ï¼‰
        front_transform = cube_transforms.get('front', {})
        if front_transform.get('visible', True):
            faces_to_draw.append({
                'frame': frame1_resized,
                'transform': front_transform,
                'name': 'front'
            })
        
        # å³ä¾§é¢ï¼ˆvideo2ï¼‰
        right_transform = cube_transforms.get('right', {})
        if right_transform.get('visible', True):
            faces_to_draw.append({
                'frame': frame2_resized,
                'transform': right_transform,
                'name': 'right'
            })
        
        # æŒ‰Zå€¼æ’åºï¼ˆå…ˆç»˜åˆ¶è¿œçš„é¢ï¼‰
        faces_to_draw.sort(key=lambda x: x['transform'].get('zIndex', 0))
        
        # ç»˜åˆ¶æ‰€æœ‰é¢
        for face_data in faces_to_draw:
            frame = face_data['frame']
            transform = face_data['transform']
            rect = transform.get('rect', {})
            
            x = rect.get('x', 0)
            y = rect.get('y', 0)
            w = rect.get('width', cube_size)
            h = rect.get('height', cube_size)
            
            # ç®€å•çš„è¾¹ç•Œæ£€æŸ¥
            if w <= 0 or h <= 0:
                continue
            
            # ç›´æ¥ä½¿ç”¨rectçš„å°ºå¯¸è¿›è¡Œç¼©æ”¾ï¼ˆPlaywrightå·²ç»è®¡ç®—å¥½é€è§†ï¼‰
            try:
                # ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸
                frame_scaled = cv2.resize(frame, (int(w), int(h)), interpolation=cv2.INTER_LINEAR)
                
                # è®¡ç®—ç»˜åˆ¶ä½ç½®
                draw_x = int(x)
                draw_y = int(y)
                draw_w = int(w)
                draw_h = int(h)
                
                # è£å‰ªåˆ°ç”»å¸ƒèŒƒå›´å†…
                src_x1 = 0
                src_y1 = 0
                src_x2 = draw_w
                src_y2 = draw_h
                
                dst_x1 = draw_x
                dst_y1 = draw_y
                dst_x2 = draw_x + draw_w
                dst_y2 = draw_y + draw_h
                
                # å¤„ç†è´Ÿåæ ‡
                if dst_x1 < 0:
                    src_x1 = -dst_x1
                    dst_x1 = 0
                if dst_y1 < 0:
                    src_y1 = -dst_y1
                    dst_y1 = 0
                
                # å¤„ç†è¶…å‡ºè¾¹ç•Œ
                if dst_x2 > width:
                    src_x2 -= (dst_x2 - width)
                    dst_x2 = width
                if dst_y2 > height:
                    src_y2 -= (dst_y2 - height)
                    dst_y2 = height
                
                # ç¡®ä¿æœ‰æœ‰æ•ˆçš„ç»˜åˆ¶åŒºåŸŸ
                if dst_x2 > dst_x1 and dst_y2 > dst_y1 and src_x2 > src_x1 and src_y2 > src_y1:
                    canvas[dst_y1:dst_y2, dst_x1:dst_x2] = frame_scaled[src_y1:src_y2, src_x1:src_x2]
            except Exception as e:
                print(f"Warning: Error drawing face {face_data['name']}: {e}")
                pass
        
        return canvas
    
    def _calculate_z_index(self, face_transform):
        """è®¡ç®—é¢çš„Zç´¢å¼•ï¼ˆç”¨äºæ·±åº¦æ’åºï¼‰"""
        transform_str = face_transform.get('transform', 'none')
        
        if transform_str == 'none':
            return 0
        
        # ç®€å•æå–translateZå€¼
        if 'translateZ' in transform_str:
            try:
                z_value = float(transform_str.split('translateZ(')[1].split('px)')[0])
                return z_value
            except:
                return 0
        
        return 0
    
    def _extract_video_frames(self, video_tensor):
        """ä»è§†é¢‘tensorä¸­æå–å¸§"""
        frames = []
        
        if video_tensor.dim() == 4:
            batch_size = video_tensor.shape[0]
            for i in range(batch_size):
                frame = video_tensor[i]
                frames.append(frame)
        else:
            frames.append(video_tensor)
        
        return frames
    
    def _tensor_to_numpy(self, frame_tensor):
        """å°†tensorè½¬æ¢ä¸ºnumpyæ•°ç»„"""
        if isinstance(frame_tensor, torch.Tensor):
            frame_np = frame_tensor.cpu().numpy()
        else:
            frame_np = frame_tensor
        
        # è½¬æ¢æ•°æ®ç±»å‹
        if frame_np.dtype == np.float32 or frame_np.dtype == np.float64:
            frame_np = (frame_np * 255).clip(0, 255).astype(np.uint8)
        
        return frame_np
    
    def _numpy_to_base64(self, frame_np):
        """å°†numpyæ•°ç»„è½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        import io
        import base64
        from PIL import Image
        
        # ç¡®ä¿æ˜¯uint8ç±»å‹
        if frame_np.dtype != np.uint8:
            frame_np = (frame_np * 255).clip(0, 255).astype(np.uint8)
        
        # è½¬æ¢ä¸ºPILå›¾ç‰‡
        image = Image.fromarray(frame_np, mode='RGB')
        
        # è½¬æ¢ä¸ºbase64
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        
        return f"data:image/png;base64,{img_str}"
    
    def _parse_background_color(self, color_str):
        """è§£æèƒŒæ™¯é¢œè‰²å­—ç¬¦ä¸²ä¸ºBGRå…ƒç»„"""
        if color_str.startswith('#'):
            hex_color = color_str[1:]
            r = int(hex_color[0:2], 16)
            g = int(hex_color[2:4], 16)
            b = int(hex_color[4:6], 16)
            return (b, g, r)
        else:
            return (0, 0, 0)
    
    def _frames_to_tensor(self, frames):
        """å°†å¸§åˆ—è¡¨è½¬æ¢ä¸ºè§†é¢‘tensor"""
        if not frames:
            return torch.zeros((1, 640, 640, 3), dtype=torch.float32)
        
        frame_tensors = []
        for frame in frames:
            if isinstance(frame, np.ndarray):
                frame_tensor = torch.from_numpy(frame).float() / 255.0
                frame_tensors.append(frame_tensor)
            else:
                frame_tensors.append(frame)
        
        video_tensor = torch.stack(frame_tensors, dim=0)
        
        return video_tensor


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "VideoCubeTransitionNode": VideoCubeTransitionNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoCubeTransitionNode": "Video Cube Transition",
}

