"""
Playwrightæ¸²æŸ“å™¨åŸºç±»
æä¾›åŸºç¡€çš„HTMLæ¸²æŸ“å’Œæˆªå›¾åŠŸèƒ½
"""

import os
import tempfile
import shutil
from pathlib import Path
from typing import List, Optional

import io
import torch
import numpy as np
from PIL import Image

try:
    from playwright.async_api import async_playwright, Page, Browser
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    print("âš ï¸  Playwrightæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install playwright && playwright install chromium")


class PlaywrightRenderer:
    """Playwrightæ¸²æŸ“å™¨åŸºç±»"""
    
    def __init__(self):
        self.playwright = None
        self.browser = None
        self.temp_dir = None
        
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼šè¿›å…¥"""
        if not PLAYWRIGHT_AVAILABLE:
            raise RuntimeError("Playwrightæœªå®‰è£…")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = Path(tempfile.mkdtemp(prefix="comfyui_playwright_"))
        
        # å¯åŠ¨Playwright
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=True,
            args=[
                '--disable-gpu',  # å…ˆç¦ç”¨GPUï¼Œç¡®ä¿ç¨³å®šæ€§
                '--disable-dev-shm-usage',
                '--disable-software-rasterizer',
                '--disable-extensions',
                '--disable-background-networking',
                '--disable-sync',
                '--disable-translate',
                '--hide-scrollbars',
                '--metrics-recording-only',
                '--mute-audio',
                '--no-first-run',
            ]
        )
        
        print("âœ… Playwrightå¯åŠ¨æˆåŠŸ")
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼šé€€å‡º"""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
        if self.temp_dir and self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)
        
    async def render_frames(
        self, 
        html_content: str, 
        duration: float, 
        fps: int,
        width: int = 1920,
        height: int = 1080
    ) -> torch.Tensor:
        """
        æ¸²æŸ“HTMLç”Ÿæˆè§†é¢‘å¸§
        
        Args:
            html_content: HTMLå†…å®¹
            duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            fps: å¸§ç‡
            width: å®½åº¦
            height: é«˜åº¦
            
        Returns:
            torch.Tensor: è§†é¢‘å¸§ [B, H, W, C]
        """
        total_frames = int(duration * fps)
        frames = []
        
        # åˆ›å»ºé¡µé¢
        page = await self.browser.new_page(viewport={'width': width, 'height': height})
        
        try:
            # åŠ è½½HTML
            await page.set_content(html_content, wait_until='domcontentloaded', timeout=30000)
            
            # ç­‰å¾…åˆå§‹åŒ–
            await page.wait_for_function("window.effectReady === true", timeout=5000)
            
            print(f"ğŸ“¹ å¼€å§‹æ¸²æŸ“ {total_frames} å¸§...")
            
            # æ¸²æŸ“æ¯ä¸€å¸§
            for i in range(total_frames):
                progress = i / max(total_frames - 1, 1)
                
                # æ›´æ–°åŠ¨ç”»çŠ¶æ€
                await page.evaluate(f"window.updateEffect({progress})")
                
                # ç­‰å¾…æ¸²æŸ“å®Œæˆ
                await page.wait_for_timeout(16)  # çº¦ç­‰äº60fpsçš„ä¸€å¸§æ—¶é—´
                
                # æˆªå›¾
                screenshot_bytes = await page.screenshot()
                
                # è½¬æ¢ä¸ºtensor
                image = Image.open(io.BytesIO(screenshot_bytes)).convert('RGB')
                array = np.array(image).astype(np.float32) / 255.0
                tensor = torch.from_numpy(array)
                frames.append(tensor)
                
                # è¿›åº¦æç¤º
                if (i + 1) % 10 == 0 or i == total_frames - 1:
                    print(f"   æ¸²æŸ“è¿›åº¦: {i + 1}/{total_frames} ({(i + 1) / total_frames * 100:.1f}%)")
            
            # å †å ä¸ºè§†é¢‘tensor [B, H, W, C]
            video_tensor = torch.stack(frames, dim=0)
            
            print(f"âœ… æ¸²æŸ“å®Œæˆï¼è¾“å‡ºå½¢çŠ¶: {video_tensor.shape}")
            
            return video_tensor
            
        finally:
            await page.close()
    
    def save_image_to_temp(self, image_tensor: torch.Tensor, filename: str) -> str:
        """
        ä¿å­˜å›¾ç‰‡åˆ°ä¸´æ—¶ç›®å½•
        
        Args:
            image_tensor: å›¾ç‰‡tensor [H, W, C]
            filename: æ–‡ä»¶å
            
        Returns:
            str: æ–‡ä»¶è·¯å¾„
        """
        # è½¬æ¢ä¸ºnumpy
        if image_tensor.dim() == 4:
            image_tensor = image_tensor[0]
        
        array = image_tensor.cpu().numpy()
        
        # è½¬æ¢æ•°æ®ç±»å‹
        if array.dtype == np.float32 or array.dtype == np.float64:
            array = (array * 255).clip(0, 255).astype(np.uint8)
        
        # ä¿å­˜å›¾ç‰‡
        image = Image.fromarray(array, mode='RGB')
        filepath = self.temp_dir / filename
        image.save(filepath)
        
        return str(filepath)


