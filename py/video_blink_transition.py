"""
è§†é¢‘çœ¨çœ¼è½¬åœºèŠ‚ç‚¹ - çº¯Pythonå®ç°

æ•ˆæœæè¿°ï¼š
- ä¸Šä¸‹é»‘è‰²é®ç½©æ¨¡æ‹Ÿçœ¼ç‘é—­åˆ
- ä¸­é—´éœ²å‡ºæ­£å¸¸å›¾ç‰‡ï¼ˆå¸¦æ¨¡ç³Šï¼‰
- çœ¨çœ¼ç¬é—´å®Œæˆè§†é¢‘åˆ‡æ¢

æŠ€æœ¯å®ç°ï¼š
- ä½¿ç”¨ NumPy æ•°ç»„æ“ä½œå®ç°é®ç½©
- ä½¿ç”¨ cv2.GaussianBlur å®ç°æ¨¡ç³Šæ•ˆæœ
- çº¯Pythonå¤„ç†ï¼Œæ— éœ€Playwrightï¼Œæ€§èƒ½æå‡50%+
"""

import time
import numpy as np
import torch
import cv2
from comfy.comfy_types.node_typing import ComfyNodeABC, InputTypeDict, IO


class VideoBlinkTransitionNode(ComfyNodeABC):
    """è§†é¢‘çœ¨çœ¼è½¬åœºèŠ‚ç‚¹ - çº¯Pythonå®ç°"""
    
    CATEGORY = "VideoTransition"
    
    @classmethod
    def INPUT_TYPES(cls) -> InputTypeDict:
        return {
            "required": {
                "video1": (IO.IMAGE,),
                "video2": (IO.IMAGE,),
                "total_frames": (IO.INT, {"default": 60, "min": 4, "max": 300}),
                "fps": (IO.INT, {"default": 30, "min": 15, "max": 60}),
            },
            "optional": {
                "blink_speed": (IO.FLOAT, {"default": 1.0, "min": 0.3, "max": 3.0, "step": 0.1}),  # çœ¨çœ¼é€Ÿåº¦
                "blur_intensity": (IO.FLOAT, {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1}),  # æ¨¡ç³Šå¼ºåº¦
                "eyelid_curve": (IO.FLOAT, {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.05}),  # çœ¼ç‘å¼§åº¦
                "edge_feather": (IO.FLOAT, {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.05}),  # è¾¹ç¼˜ç¾½åŒ–
                "mask_color": ([
                    "black",    # é»‘è‰²ï¼ˆæ¨èï¼‰
                    "white",    # ç™½è‰²
                    "gray",     # ç°è‰²
                ],),
            }
        }
    
    RETURN_TYPES = (IO.IMAGE,)
    RETURN_NAMES = ("video",)
    FUNCTION = "generate_blink_transition"
    
    def generate_blink_transition(
        self, 
        video1, 
        video2,
        total_frames,
        fps,
        blink_speed=1.0,
        blur_intensity=0.8,
        eyelid_curve=0.3,
        edge_feather=0.2,
        mask_color="black"
    ):
        """ç”Ÿæˆçœ¨çœ¼è½¬åœºæ•ˆæœ - çº¯Pythonå®ç°"""
        
        start_time = time.time()
        
        print(f"ğŸ‘ï¸ å¼€å§‹ç”Ÿæˆçœ¨çœ¼è½¬åœºæ•ˆæœï¼ˆçº¯Pythonç‰ˆï¼‰...")
        print(f"   å¸§ç‡: {fps} FPS")
        print(f"   çœ¨çœ¼é€Ÿåº¦: {blink_speed}")
        print(f"   æ¨¡ç³Šå¼ºåº¦: {blur_intensity}")
        print(f"   çœ¼ç‘å¼§åº¦: {eyelid_curve}")
        print(f"   è¾¹ç¼˜ç¾½åŒ–: {edge_feather}")
        print(f"   é®ç½©é¢œè‰²: {mask_color}")
        
        # æå–è§†é¢‘å¸§
        frames1 = self._extract_video_frames(video1)
        frames2 = self._extract_video_frames(video2)
        
        # è·å–è§†é¢‘å°ºå¯¸
        height, width = frames1[0].shape[:2]
        print(f"   è§†é¢‘å°ºå¯¸: {width}x{height}")
        
        # é®ç½©é¢œè‰²æ˜ å°„
        mask_colors = {
            "black": (0, 0, 0),
            "white": (1, 1, 1),
            "gray": (0.5, 0.5, 0.5),
        }
        mask_rgb = mask_colors.get(mask_color, (0, 0, 0))
        
        # ç”Ÿæˆæ‰€æœ‰å¸§
        output_frames = []
        
        for i in range(total_frames):
            progress = i / (total_frames - 1) if total_frames > 1 else 0
            
            # è·å–å½“å‰å¸§
            frame1 = frames1[i % len(frames1)]
            frame2 = frames2[i % len(frames2)]
            
            # ç”Ÿæˆçœ¨çœ¼å¸§
            blink_frame = self._generate_blink_frame(
                frame1, frame2, progress, 
                blink_speed, blur_intensity, eyelid_curve, edge_feather,
                mask_rgb, height, width
            )
            
            output_frames.append(blink_frame)
            
            # æ‰“å°è¿›åº¦
            if (i + 1) % 10 == 0 or i == total_frames - 1:
                progress_percent = (i + 1) / total_frames * 100
                print(f"   è¿›åº¦: {progress_percent:.1f}% ({i+1}/{total_frames})")
        
        # è½¬æ¢ä¸ºtensor
        video_tensor = self._frames_to_tensor(output_frames)
        
        total_time = time.time() - start_time
        print(f"âœ… çœ¨çœ¼è½¬åœºç”Ÿæˆå®Œæˆï¼")
        print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"ğŸš€ å¹³å‡æ¯å¸§: {total_time/total_frames*1000:.1f}ms")
        
        return (video_tensor,)
    
    def _generate_blink_frame(self, frame1, frame2, progress, 
                             blink_speed, blur_intensity, eyelid_curve, edge_feather,
                             mask_rgb, height, width):
        """ç”Ÿæˆå•å¸§çœ¨çœ¼æ•ˆæœ"""
        
        # è®¡ç®—çœ¨çœ¼é®ç½©é«˜åº¦ï¼ˆæ­£å¼¦æ›²çº¿ï¼š0â†’0.5â†’0ï¼‰
        blink_curve = abs(np.sin(progress * np.pi * blink_speed))
        mask_height_ratio = blink_curve * 0.5  # æœ€å¤§50%é«˜åº¦
        
        # è®¡ç®—æ¨¡ç³Šå¼ºåº¦ï¼ˆä¸­é—´æ—¶åˆ»æœ€æ¨¡ç³Šï¼‰
        blur_curve = np.sin(progress * np.pi)  # 0â†’1â†’0
        blur_kernel_size = int(blur_curve * blur_intensity * 20) * 2 + 1  # ç¡®ä¿ä¸ºå¥‡æ•°
        blur_kernel_size = max(1, blur_kernel_size)  # è‡³å°‘ä¸º1
        
        # é€‰æ‹©å½“å‰æ˜¾ç¤ºçš„è§†é¢‘ï¼ˆçœ¨çœ¼ç¬é—´åˆ‡æ¢ï¼‰
        if progress < 0.5:
            current_frame = frame1.copy()
        else:
            current_frame = frame2.copy()
        
        # åº”ç”¨æ¨¡ç³Šæ•ˆæœ
        if blur_kernel_size > 1:
            current_frame = cv2.GaussianBlur(current_frame, (blur_kernel_size, blur_kernel_size), 0)
        
        # è®¡ç®—é®ç½©é«˜åº¦ï¼ˆåƒç´ ï¼‰
        mask_height = int(mask_height_ratio * height)
        
        # åº”ç”¨å¼§å½¢çœ¼ç‘é®ç½©
        if mask_height > 0 and eyelid_curve > 0:
            # åˆ›å»ºå¼§å½¢é®ç½©
            self._apply_curved_eyelid_mask(
                current_frame, mask_height, eyelid_curve, edge_feather,
                mask_rgb, height, width
            )
        elif mask_height > 0 and edge_feather > 0:
            # å¹³è¡Œé®ç½©ï¼ˆeyelid_curve=0æ—¶ï¼‰ä½†å¸¦ç¾½åŒ–
            self._apply_feathered_straight_mask(
                current_frame, mask_height, edge_feather,
                mask_rgb, height, width
            )
        elif mask_height > 0:
            # å¹³è¡Œé®ç½©æ— ç¾½åŒ–
            current_frame[:mask_height, :] = mask_rgb
            current_frame[-mask_height:, :] = mask_rgb
        
        return current_frame
    
    def _apply_curved_eyelid_mask(self, frame, mask_height, curve_intensity, edge_feather,
                                  mask_rgb, height, width):
        """åº”ç”¨å¼§å½¢çœ¼ç‘é®ç½©ï¼ˆå¸¦ç¾½åŒ–ï¼‰- ä¿®æ­£ç‰ˆ"""
        
        # è®¡ç®—å¼§åº¦å‚æ•°
        curve_depth = int(mask_height * curve_intensity * 0.5)  # å¼§å½¢æ·±åº¦
        feather_pixels = int(mask_height * edge_feather)  # ç¾½åŒ–åƒç´ æ•°
        
        # åˆ›å»ºxåæ ‡çš„å½’ä¸€åŒ–æ•°ç»„
        normalized_x = np.linspace(-1, 1, width)
        
        # ä¸Šçœ¼ç‘é®ç½©ï¼ˆä»ä¸Šå‘ä¸‹çš„å¼§å½¢ï¼Œä¸­é—´æ·±å…¥ï¼Œä¸¤è¾¹æµ…ï¼‰
        # æŠ›ç‰©çº¿ï¼šy = curve_depth * x^2ï¼Œä¸­é—´æ˜¯0ï¼Œä¸¤è¾¹æ˜¯curve_depth
        parabola_top = curve_depth * (normalized_x ** 2)
        
        # éå†å¯èƒ½è¢«é®ç½©å½±å“çš„åŒºåŸŸ
        max_y = int(mask_height + curve_depth + feather_pixels)
        for y in range(max_y):
            # è®¡ç®—è¿™ä¸€è¡Œçš„å¼§å½¢è¾¹ç•Œï¼ˆä¸­é—´æ·±ï¼Œä¸¤è¾¹æµ…ï¼‰
            boundary = mask_height + parabola_top  # ä¸¤è¾¹é«˜ï¼Œä¸­é—´ä½
            
            # è®¡ç®—è·ç¦»ï¼ˆè´Ÿæ•°=åœ¨é®ç½©å†…ï¼Œæ­£æ•°=åœ¨é®ç½©å¤–ï¼‰
            distance = boundary - y
            
            if feather_pixels > 0:
                # ç¾½åŒ–ï¼šdistance > 0 è¡¨ç¤ºåœ¨é®ç½©å†…
                # alpha = 1 (å®Œå…¨é®ç½©) åˆ° 0 (å®Œå…¨é€æ˜)
                alpha = np.clip(distance / feather_pixels, 0, 1)
            else:
                # æ— ç¾½åŒ–ï¼šç¡¬è¾¹ç¼˜
                alpha = (distance > 0).astype(float)
            
            # åº”ç”¨é®ç½©ï¼ˆalpha=1æ—¶å®Œå…¨æ˜¯mask_rgbï¼Œalpha=0æ—¶å®Œå…¨æ˜¯åŸå›¾ï¼‰
            frame[y, :] = frame[y, :] * (1 - alpha[:, np.newaxis]) + np.array(mask_rgb) * alpha[:, np.newaxis]
        
        # ä¸‹çœ¼ç‘é®ç½©ï¼ˆä»ä¸‹å‘ä¸Šçš„å¼§å½¢ï¼Œä¸­é—´æ·±å…¥ï¼Œä¸¤è¾¹æµ…ï¼‰
        parabola_bottom = curve_depth * (normalized_x ** 2)
        
        # éå†å¯èƒ½è¢«é®ç½©å½±å“çš„åŒºåŸŸ
        min_y = int(height - mask_height - curve_depth - feather_pixels)
        for y in range(min_y, height):
            # è®¡ç®—è¿™ä¸€è¡Œçš„å¼§å½¢è¾¹ç•Œï¼ˆä¸­é—´æ·±ï¼Œä¸¤è¾¹æµ…ï¼‰
            boundary = height - mask_height - parabola_bottom  # ä¸¤è¾¹é«˜ï¼Œä¸­é—´ä½
            
            # è®¡ç®—è·ç¦»ï¼ˆè´Ÿæ•°=åœ¨é®ç½©å¤–ï¼Œæ­£æ•°=åœ¨é®ç½©å†…ï¼‰
            distance = y - boundary
            
            if feather_pixels > 0:
                # ç¾½åŒ–ï¼šdistance > 0 è¡¨ç¤ºåœ¨é®ç½©å†…
                alpha = np.clip(distance / feather_pixels, 0, 1)
            else:
                # æ— ç¾½åŒ–ï¼šç¡¬è¾¹ç¼˜
                alpha = (distance > 0).astype(float)
            
            # åº”ç”¨é®ç½©
            frame[y, :] = frame[y, :] * (1 - alpha[:, np.newaxis]) + np.array(mask_rgb) * alpha[:, np.newaxis]
    
    def _apply_feathered_straight_mask(self, frame, mask_height, edge_feather,
                                      mask_rgb, height, width):
        """åº”ç”¨å¹³è¡Œé®ç½©ï¼ˆå¸¦ç¾½åŒ–ï¼‰"""
        
        feather_pixels = int(mask_height * edge_feather)
        
        # ä¸Šé®ç½©å¸¦ç¾½åŒ–
        for y in range(mask_height + feather_pixels):
            if y < mask_height:
                # å®Œå…¨é®ç½©åŒºåŸŸ
                frame[y, :] = mask_rgb
            else:
                # ç¾½åŒ–åŒºåŸŸ
                distance = y - mask_height
                alpha = 1 - (distance / feather_pixels)
                frame[y, :] = frame[y, :] * (1 - alpha) + np.array(mask_rgb) * alpha
        
        # ä¸‹é®ç½©å¸¦ç¾½åŒ–
        for y in range(height - mask_height - feather_pixels, height):
            if y >= height - mask_height:
                # å®Œå…¨é®ç½©åŒºåŸŸ
                frame[y, :] = mask_rgb
            else:
                # ç¾½åŒ–åŒºåŸŸ
                distance = (height - mask_height) - y
                alpha = 1 - (distance / feather_pixels)
                frame[y, :] = frame[y, :] * (1 - alpha) + np.array(mask_rgb) * alpha
    
    def _extract_video_frames(self, video_tensor):
        """æå–è§†é¢‘å¸§"""
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(video_tensor, torch.Tensor):
            video_array = video_tensor.cpu().numpy()
        else:
            video_array = video_tensor
        
        # ç¡®ä¿æ•°æ®åœ¨[0,1]èŒƒå›´å†…
        video_array = np.clip(video_array, 0, 1)
        
        if len(video_array.shape) == 4:  # [frames, height, width, channels]
            return [video_array[i] for i in range(video_array.shape[0])]
        else:  # å•å¸§
            return [video_array]
    
    def _frames_to_tensor(self, frames):
        """å¸§åˆ—è¡¨è½¬tensor"""
        frames_array = np.array(frames)
        return torch.from_numpy(frames_array).float()


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "VideoBlinkTransitionNode": VideoBlinkTransitionNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoBlinkTransitionNode": "Video Blink Transition"
}

